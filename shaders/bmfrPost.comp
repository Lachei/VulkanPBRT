#version 460

#include "bmfrGeneral.comp" //includes all layout declarations and common functions

void main(){
    float pixelSpp = 0;
    ivec2 imSize = ivec2(IMAGE_WIDTH, IMAGE_HEIGHT);
    ivec2 curAbsolutPos = ivec2(gl_GlobalInvocationID.xy) - ivec2(vec2(BLOCK_WIDTH, BLOCK_HEIGHT) * pixelOffsets[camParams.frameNumber % 16]);
    ivec2 curImagePos = mirror(curAbsolutPos, imSize);
    float features[ALPHA_SIZE - 3];

    //--------------------------------------------------------------------------
    // Loading all features and samples
    //--------------------------------------------------------------------------
    vec3 noisyColor = texelFetch(noisy, curImagePos, 0).xyz;
    vec3 pos;
    pos.z = imageLoad(depth, curImagePos).x;
    vec2 compressedNormal = imageLoad(normal, curImagePos).xy;
    vec3 normal;
    normal.x = cos(compressedNormal.y) * sin(compressedNormal.x);
    normal.y = sin(compressedNormal.y) * sin(compressedNormal.x);
    normal.z = cos(compressedNormal.x);
    vec2 prevFrameUv = imageLoad(motion, curImagePos).xy;
    bool pixelAccept = prevFrameUv.x >= 0;
    pixelSpp = imageLoad(samples, curImagePos).x * 256;
    
    //--------------------------------------------------------------------------
    // normalizing depth and filling the feature maps
    //--------------------------------------------------------------------------
    // normalizing world depth
    switch(POSITION_TYPE){
    case POSITION_DEPTH:{
        float min_val = parallel_reduction_min(pos.z);
        float max_val = parallel_reduction_max(pos.z);
        pos.z -= min_val;
        pos.z /= max_val - min_val + EPS;
        pos.xy = vec2(gl_LocalInvocationID.xy) / (vec2(BLOCK_WIDTH, BLOCK_HEIGHT) - vec2(1));
        break;
    }
    case POSITION_WORLD_DEPTH_NORM:{
        float min_val = parallel_reduction_min(pos.z);
        float max_val = parallel_reduction_max(pos.z);
        pos.z -= min_val;
        pos.z /= max_val - min_val + EPS;
        vec2 pixelCenter = vec2(curImagePos) + vec2(.5);
	    const vec2 normalisedPixelCoord = pixelCenter/vec2(imSize);
	    vec2 clipSpaceCoord = normalisedPixelCoord * 2.0 - 1.0;

	    vec4 worldSpacePos = camParams.inverseViewMatrix * vec4(0,0,0,1);
	    vec4 viewSpaceDir = camParams.inverseProjectionMatrix * vec4(clipSpaceCoord.x, clipSpaceCoord.y, 1, 1) ;
	    vec4 worldSpaceDir = camParams.inverseViewMatrix * vec4(normalize(viewSpaceDir.xyz), 0) ;
        pos.xyz = worldSpaceDir.xyz * pos.z;
        break;
    }
    case POSITION_WORLD:{
        vec2 pixelCenter = vec2(curImagePos) + vec2(.5);
	    const vec2 normalisedPixelCoord = pixelCenter/vec2(imSize);
	    vec2 clipSpaceCoord = normalisedPixelCoord * 2.0 - 1.0;

	    vec4 worldSpacePos = camParams.inverseViewMatrix * vec4(0,0,0,1);
	    vec4 viewSpaceDir = camParams.inverseProjectionMatrix * vec4(clipSpaceCoord.x, clipSpaceCoord.y, 1, 1) ;
	    vec4 worldSpaceDir = camParams.inverseViewMatrix * vec4(normalize(viewSpaceDir.xyz), 0) ;
        pos.xyz = worldSpacePos.xyz + worldSpaceDir.xyz * pos.z;
        for(int i = 0; i < 3; ++i){
            float min_val = parallel_reduction_min(pos[i]);
            float max_val = parallel_reduction_max(pos[i]);
            pos[i] -= min_val;
            pos[i] /= max_val - min_val + EPS;
        }
        break;
    }
    }
    //only calculating for pixels inside the image domain
    if(curAbsolutPos != curImagePos) return;
    vec2 screenPos = vec2(gl_LocalInvocationID.xy) / (vec2(BLOCK_WIDTH, BLOCK_HEIGHT) - vec2(1));

    features= float[ALPHA_SIZE - 3](
        1.,
        normal.x,
        normal.y,
        normal.z,
        pos.x,
        pos.y,
        pos.z,
        pos.x * pos.x,
        pos.y * pos.y,
        pos.z * pos.z
    );

    // weighted sum calculation
    vec3 denoisedColor = vec3(0);
    vec3 weight;
    for(int feature = 0; feature < ALPHA_SIZE - 3; ++feature){
        weight.x = imageLoad(weights, ivec3(gl_WorkGroupID.xy, feature * 3)).x;
        weight.y = imageLoad(weights, ivec3(gl_WorkGroupID.xy, feature * 3 + 1)).x;
        weight.z = imageLoad(weights, ivec3(gl_WorkGroupID.xy, feature * 3 + 2)).x;
        if(isinf(weight.x) || isnan(weight.x)) weight.x = 0;
        if(isinf(weight.y) || isnan(weight.y)) weight.y = 0;
        if(isinf(weight.z) || isnan(weight.z)) weight.z = 0;
        denoisedColor += weight * features[feature];
    }

    denoisedColor = clamp(denoisedColor, vec3(0), vec3(10));

    //--------------------------------------------------------------------------
    //  Data accumulation
    //--------------------------------------------------------------------------
    vec3 prevAccColor = vec3(0);
    float blendAlpha = 1;
    if( camParams.frameNumber > 0 && pixelAccept){
        prevAccColor += texture(denoisedSampled, vec3(prevFrameUv.xy, camParams.frameNumber & 1)).xyz;
        blendAlpha = max(1.f / pixelSpp, SECOND_BLEND_ALPHA);
    }

    //averaging up with previoius color and storing the results (This is still only lighting without surface albedo color)
    denoisedColor = blendAlpha * denoisedColor + (1 - blendAlpha) * prevAccColor;

    imageStore(denoised, ivec3(curImagePos,(camParams.frameNumber & 1) ^ 1), vec4(denoisedColor,1));

    //remodulate albedo and tone map
    vec3 albedo = imageLoad(albedo, curImagePos).xyz + vec3(EPS);
    vec3 toneMappedColor = clamp(pow(max(vec3(0),albedo * denoisedColor),vec3(.454545f)),0,1);
    imageStore(finalImage, ivec2(curImagePos), vec4(toneMappedColor, 1));
}