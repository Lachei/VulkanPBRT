#version 450

#pragma import_defines(SEPARATE_MATRICES)

layout(binding = 0) uniform sampler2D srcImage;
layout(binding = 1, r32f) uniform image2D depthImage;
layout(binding = 2, rg32f) uniform image2D normalImage;
layout(binding = 3, rgba8) uniform image2D materialImage;
layout(binding = 4, rgba8) uniform image2D albedoImage;
layout(binding = 5) uniform sampler2D prevDepth;
layout(binding = 6) uniform sampler2D prevNormal;
layout(binding = 7, r16f) uniform image2D motion;
layout(binding = 8, r8) uniform image2D sampleCounts;
layout(binding = 9) uniform sampler2D prevSampleCounts;
layout(binding = 10) uniform sampler2D prevOutput;
layout(binding = 11, rgba16f) uniform image2D illumination;
layout(binding = 12) uniform sampler2D prevIlluminationSquared;
layout(binding = 13, rgba16f) uniform image2D illuminationSquared;

layout(push_constant) uniform PushConstants 
{
	mat4 view;			//for separate matrices view is the inverse projection matrix
	mat4 inverseView;
	mat4 prevView;
    vec4 prevOrigin;
	uint frameNumber;
} camParams;

layout (local_size_x_id = 0,local_size_y_id = 1,local_size_z=1) in;

const float BLEND_ALPHA = .1;

void main(){
    ivec2 imageSize = textureSize(srcImage, 0);
    if(gl_GlobalInvocationID.x >= imageSize.x || gl_GlobalInvocationID.y >= imageSize.y) return;
    vec3 prevColor;
	vec3 prevColorSquared;
    vec3 normal;
    normal.xy = imageLoad(normalImage, ivec2(gl_GlobalInvocationID.xy)).xy;
    normal = vec3(sin(normal.x) * cos(normal.y), sin(normal.x) * sin(normal.y), cos(normal.x));
	float truePrevDepth;
	bool reprojected = false;
	float pixelSpp = 1.0 / 256.0; //has to be normalized as only floating point 8 bit interp is supported
    float depth = imageLoad(depthImage, ivec2(gl_GlobalInvocationID.xy)).x;
#ifdef SEPARATE_MATRICES
	mat4 proj = inverse(camParams.view);
	vec4 pos = camParams.inverseView[3];
	pos.w = 1;
	vec2 pixelCenter = vec2(gl_GlobalInvocationID.xy) + vec2(.5);
	vec2 clipSpaceCoord = pixelCenter/vec2(textureSize(srcImage, 0).xy) * 2.0 - 1.0;
	vec4 dir = camParams.view * vec4(clipSpaceCoord, 1, 1);
	dir = camParams.inverseView * vec4(normalize(dir.xyz), 0);
	vec4 p = pos + depth * dir;
	vec4 prevPos = proj * camParams.prevView * p;
#else
    vec4 curOrigin = camParams.inverseView[2];
    curOrigin /= curOrigin.w;
    vec2 clipSpaceCoord = ((vec2(gl_GlobalInvocationID.xy) + vec2(.5)) / vec2(imageSize)) * 2 - 1;
    vec4 curDir = camParams.inverseView * vec4(clipSpaceCoord.x, clipSpaceCoord.y, 1, 1);
	curDir /= curDir.w + 1e-9;

    curDir = -normalize(curDir - curOrigin);
	vec4 p = curOrigin + depth * curDir;
	vec4 prevPos = camParams.prevView * p;
#endif
	float preDepth = length(p.xyz - camParams.prevOrigin.xyz);
	prevPos /= prevPos.w; // xy now holds the prev image position
	prevPos.xy += 1;
	prevPos.xy *= .5;
	prevPos.xy *= vec2(imageSize.xy) / vec2(imageSize.xy - .5);
	ivec2 prevPixelIndex = ivec2(prevPos.xy * (imageSize.xy - vec2(1)) + .5f);
	if(camParams.frameNumber > 0){
		//depth check
		truePrevDepth = texture(prevDepth, prevPos.xy).x;
		float depthDissim = (truePrevDepth / preDepth) - 1;	//using relative error of depths to blend pixels further away form camera together
		if(all(greaterThanEqual(prevPos.xy, vec2(0))) && all(lessThanEqual(prevPos.xy, vec2(1))) && abs(depthDissim) <= .01f){		//dissimilarity in depth values shoudl be smaller than 1%
			//normal check
			vec3 prevNor;
			prevNor.xy = texture(prevNormal, prevPos.xy).xy;
			prevNor = vec3(sin(prevNor.x) * cos(prevNor.y), sin(prevNor.x) * sin(prevNor.y), cos(prevNor.x));
			
			// TODO: enable this check once normal decompression has been fixed
			// if(dot(normal, prevNor) > .7f) //we do have a point which can be reprojected
			{	
				reprojected = true;
				prevColor = texture(prevOutput, prevPos.xy).xyz;
				pixelSpp += texture(prevSampleCounts, prevPos.xy).x;
			}
		}
	}
	if(reprojected){
		imageStore(motion, ivec2(gl_GlobalInvocationID.xy), vec4(prevPos.xy, 1, 1));
	}
	else{
		imageStore(motion, ivec2(gl_GlobalInvocationID.xy), vec4(-1));
	}
	imageStore(sampleCounts, ivec2(gl_GlobalInvocationID.xy), vec4(pixelSpp));

    vec3 demodulated = texelFetch(srcImage, ivec2(gl_GlobalInvocationID.xy), 0).xyz;
	if(reprojected){
		float blendAlpha = max(1.f / (pixelSpp * 256.0), BLEND_ALPHA);
		demodulated = mix(prevColor, demodulated, blendAlpha);
	}
	imageStore(illumination, ivec2(gl_GlobalInvocationID.xy), vec4(demodulated, 1));
}